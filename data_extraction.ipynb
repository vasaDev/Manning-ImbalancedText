import numpy as np
from collections import Counter
import tensorflow as tf

(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(path='imdb.npz',num_words=None, skip_top=0,maxlen =None, seed=113, start_char=1, oov_char=2, index_from=3)

def concatTrains(x, y):
    return (x, y)

positive_reviews = []
negative_reviews = []
for i in range(0, len(x_train)):
    if y_train[i] == 1:
        positive_reviews.append(x_train[i])
    elif  y_train[i] == 0:
        negative_reviews.append(x_train[i])
        
positive_reviews_lengths = []
for i in range(0, len(positive_reviews)):
    positive_reviews_lengths.append(len(positive_reviews[i]))
    
positive_result = Counter(positive_reviews_lengths).most_common(1)
print('The most frequent length for positive review is', positive_result[0][0], 'words and it occurs', positive_result[0][1], 'times')

negative_reviews_lengths = []
for i in range(0, len(negative_reviews)):
    negative_reviews_lengths.append(len(negative_reviews[i]))

negative_result = Counter(negative_reviews_lengths).most_common(1)
print('The most frequent length for negative review is', negative_result[0][0], 'words and it occurs', negative_result[0][1], 'times')

import seaborn as sns
from matplotlib import pyplot as plt

sns.set_style('darkgrid')
fig, ax = plt.subplots()
sns.distplot(positive_reviews_lengths, label='positive_review_lengths')
sns.distplot(negative_reviews_lengths, label='negative_review_lengths')
ax.legend()
ax.set(xlabel='total word count', ylabel='frequency of occurence')
